import 'dotenv/config';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { Pool } from 'pg';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const pool = new Pool({ connectionString: process.env.DATABASE_URL });

async function runSQL(client, filePath){
  const sql = fs.readFileSync(filePath, 'utf8');
  await client.query(sql);
  console.log('âœ“', path.basename(filePath));
}

(async () => {
  const client = await pool.connect();
  try {
    await client.query('begin');
    // 1) base schema
    await runSQL(client, path.join(__dirname, 'db.sql'));
    // 2) incremental migrations
    const migDir = path.join(__dirname, 'migrations');
    if (fs.existsSync(migDir)) {
      const files = fs.readdirSync(migDir)
        .filter(f => f.endsWith('.sql'))
        .sort();
      for (const f of files) {
        await runSQL(client, path.join(migDir, f));
      }
    }
    await client.query('commit');
    console.log('Migration completed.');
  } catch(e){
    await client.query('rollback');
    console.error(e);
    process.exit(1);
  } finally {
    client.release();
    process.exit(0);
  }
})();
